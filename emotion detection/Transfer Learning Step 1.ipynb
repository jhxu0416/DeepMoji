{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv(\"data/clean/positive.csv\", encoding= \"utf-8\")\n",
    "positive = list(positive[\"text\"])\n",
    "slightly_positive = pd.read_csv(\"data/clean/slightly_positive.csv\", encoding= \"utf-8\")\n",
    "slightly_positive = list(slightly_positive[\"text\"])\n",
    "slightly_negative = pd.read_csv(\"data/clean/slightly_negative.csv\", encoding= \"utf-8\")\n",
    "slightly_negative = list(slightly_negative[\"text\"])\n",
    "negative = pd.read_csv(\"data/clean/negative.csv\", encoding= \"utf-8\")\n",
    "negative = list(negative[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use DeepMoji to encode texts into emotional feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import example_helper\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from deepmoji.model_def import deepmoji_feature_encoding\n",
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing using dictionary from /Users/xjh/Github/DeepMoji/model/vocabulary.json\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30\n",
    "batch_size = 32\n",
    "\n",
    "print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "st = SentenceTokenizer(vocabulary, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /Users/xjh/Github/DeepMoji/model/deepmoji_weights.hdf5.\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:488: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2585: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1370: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Loading weights for embedding\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/DeepMoji/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Loading weights for bi_lstm_0\n",
      "Loading weights for bi_lstm_1\n",
      "Loading weights for attlayer\n",
      "Ignoring weights for softmax\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 256)      12800000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 30, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 30, 1024)     3149824     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 30, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 2304)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 22,247,680\n",
      "Trainable params: 22,247,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "model = deepmoji_feature_encoding(maxlen, PRETRAINED_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_positive, _, _ = st.tokenize_sentences(positive)\n",
    "tokenized_slightly_positive, _, _ = st.tokenize_sentences(slightly_positive)\n",
    "tokenized_slightly_negative, _, _ = st.tokenize_sentences(slightly_negative)\n",
    "tokenized_negative, _, _ = st.tokenize_sentences(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts..\n",
      "Positive done\n",
      "Slightly positive done\n",
      "Slightly negative done\n",
      "Negative done\n"
     ]
    }
   ],
   "source": [
    "print('Encoding texts..')\n",
    "encoding_positive = model.predict(tokenized_positive)\n",
    "print(\"Positive done\")\n",
    "encoding_slightly_positive = model.predict(tokenized_slightly_positive)\n",
    "print(\"Slightly positive done\")\n",
    "encoding_slightly_negative = model.predict(tokenized_slightly_negative)\n",
    "print(\"Slightly negative done\")\n",
    "encoding_negative = model.predict(tokenized_negative)\n",
    "print(\"Negative done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save emotional feature vectors for shallow neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive shape (31549, 2304)\n",
      "Slightly positive shape (34806, 2304)\n",
      "Slightly negative shape (28486, 2304)\n",
      "Negative shape (37283, 2304)\n"
     ]
    }
   ],
   "source": [
    "# positive\n",
    "print(\"Positive shape {}\".format(encoding_positive.shape))\n",
    "np.save(\"data/X_positive.npy\", encoding_positive)\n",
    "\n",
    "# slightly positive\n",
    "print(\"Slightly positive shape {}\".format(encoding_slightly_positive.shape))\n",
    "np.save(\"data/X_slightly_positive.npy\", encoding_slightly_positive)\n",
    "\n",
    "# slightly negative\n",
    "print(\"Slightly negative shape {}\".format(encoding_slightly_negative.shape))\n",
    "np.save(\"data/X_slightly_negative.npy\", encoding_slightly_negative)\n",
    "\n",
    "# negative\n",
    "print(\"Negative shape {}\".format(encoding_negative.shape))\n",
    "np.save(\"data/X_negative.npy\", encoding_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepMoji)",
   "language": "python",
   "name": "deepmoji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
